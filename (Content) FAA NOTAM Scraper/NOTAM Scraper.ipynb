{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TITLE: NOTAM Scraper\n",
    "DATE: February 2023\n",
    "VERSION: 1.0\n",
    "DEVELOPER: Parker Hornstein (phornstein@esri.com)\n",
    "REQUIREMENTS: ArcGIS Notebooks\n",
    "LICENSE:\n",
    "\n",
    "Copyright Â© 2023 Esri\n",
    "\n",
    "All rights reserved under the copyright laws of the United States and applicable international laws, treaties, and conventions.\n",
    "You may freely redistribute and use this sample code, with or without modification, provided you include the original copyright notice and use restrictions.\n",
    "\n",
    "Disclaimer: THE SAMPLE CODE IS PROVIDED \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n",
    "FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL ESRI OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
    "CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n",
    "SUSTAINED BY YOU OR A THIRD PARTY, HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT ARISING IN ANY WAY OUT OF\n",
    "THE USE OF THIS SAMPLE CODE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "For additional information, contact:\n",
    "\n",
    "Esri\n",
    "Attn: Contracts and Legal Services Department\n",
    "380 New York Street\n",
    "Redlands, California, 92373-8100\n",
    "USA\n",
    "email: contracts@esri.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Parameters'''\n",
    "URL = 'https://tfr.faa.gov/tfr2/list.jsp' #FAA US NOTAMs, do not change\n",
    "BASEURL = 'https://tfr.faa.gov' #FAA URL, do not change\n",
    "NOTAM_DIR = r'/arcgis/home/notams' #processing folder in your ArcGIS Notebooks Kernal used exclusively for shapefiles\n",
    "NOTAM_LAYER_ID = '' #layer ID to NOTAM Feature Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, zipfile, arcpy, json, shutil\n",
    "from datetime import datetime as dt\n",
    "from arcgis.features import Feature\n",
    "from arcgis.gis import GIS\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "gis = GIS('home')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NOTAM():\n",
    "    '''Overhead class for manipulating data used to create NOTAM features'''\n",
    "    def __init__(self):\n",
    "        self.notam_number = None\n",
    "        self.location = None\n",
    "        self.issue_date = None\n",
    "        self.begin_dtg = None\n",
    "        self.end_dtg = None\n",
    "        self.reason = None\n",
    "        self.type = None\n",
    "        self.supercedes = None\n",
    "        self.contact = None\n",
    "        self.airspace_definition = None\n",
    "        self.altitude = None\n",
    "        self.text = None\n",
    "        self.url = None\n",
    "        self.geom = None\n",
    "   \n",
    "    @classmethod\n",
    "    def fromDict(cls,data):\n",
    "        notam = cls()\n",
    "        notam.notam_number = data.get('NOTAMNumber')\n",
    "        notam.issue_date = data.get('IssueDate')\n",
    "        notam.location = data.get('Location')\n",
    "        notam.begin_dtg = data.get('BeginningDateandTime')\n",
    "        notam.end_dtg = data.get('EndingDateandTime')\n",
    "        notam.reason = data.get('ReasonforNOTAM')\n",
    "        notam.type = data.get('Type')\n",
    "        notam.supercedes = data.get('ReplacedNOTAMs')\n",
    "        notam.contact = data.get('PilotsMayContact')\n",
    "        notam.airspace_definition = data.get('AirspaceDefinition')\n",
    "        notam.altitude = data.get('Altitude')\n",
    "        notam.text = data.get('text')\n",
    "        notam.url = data.get('url')\n",
    "        notam.geom = data.get('geom')\n",
    "        notam.convertTimeFields()\n",
    "        return notam\n",
    "    \n",
    "    def toDict(self):\n",
    "        return self.__dict__\n",
    "        \n",
    "    def convertTimeFields(self):\n",
    "        try:\n",
    "            self.issue_date = dt.strptime(self.issue_date,'%B %d, %Y at %H%M %Z')\n",
    "        except:\n",
    "            self.issue_date = None\n",
    "        try:\n",
    "            self.begin_dtg = dt.strptime(self.begin_dtg,'%B %d, %Y at %H%M %Z')\n",
    "        except:\n",
    "            self.begin_dtg = None\n",
    "        try:\n",
    "            self.end_dtg = dt.strptime(self.end_dtg,'%B %d, %Y at %H%M %Z')\n",
    "        except:\n",
    "            self.end_dtg = None\n",
    "            \n",
    "    def toFeature(self):\n",
    "        self.text = self.text[:2000]\n",
    "        attr = self.toDict().copy()\n",
    "        geom = json.loads(self.geom)\n",
    "        del attr['geom']\n",
    "        return Feature(geom,attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    '''Clean text scraped from HTML'''\n",
    "    text = text.strip().replace(' ','')\\\n",
    "                .replace(':','')\\\n",
    "                .replace('(','')\\\n",
    "                .replace(')','')\\\n",
    "                .replace('\\n','')\n",
    "    return text\n",
    "\n",
    "def searchFolder(folder_path,file_types=[]):\n",
    "    '''\n",
    "    Crawls a directory and all sub directories looking for files of specified extensions.\n",
    "    '''\n",
    "    return [os.path.join(folder_path,f) for f in os.listdir(folder_path) if f.endswith(tuple(file_types))]\n",
    "\n",
    "def cleanNOTAMDir():\n",
    "    '''\n",
    "    Empty all files in the NOTAM processing dir\n",
    "    '''\n",
    "    for filename in os.listdir(NOTAM_DIR):\n",
    "            file_path = os.path.join(NOTAM_DIR, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Request main FAA page and use BeautifulSoup to parse the HTML'''\n",
    "response = requests.get(URL)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "table = soup.find_all('table')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Find href to all NOTAM specific pages'''\n",
    "notam_urls = []\n",
    "for a in table.find_all('a', href=True):\n",
    "    if a['href'].startswith('../save_pages'):\n",
    "        notam_url = a['href']\n",
    "        notam_url = notam_url.replace('..',BASEURL)\n",
    "        notam_urls.append(notam_url)\n",
    "\n",
    "before = len(notam_urls)\n",
    "notam_urls = [*set(notam_urls)] #deduplicate URLs, webscraping can be messy so the href may exist multiple times\n",
    "f'REMOVED {before-len(notam_urls)} DUPLICATE URLS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Process the NOTAM specific page for data'''\n",
    "\n",
    "#textual keys to search for\n",
    "keys = ['NOTAMNumber','IssueDate','Location','BeginningDateandTime','EndingDateandTime',\n",
    "        'ReasonforNOTAM','Type','ReplacedNOTAMs','PilotsMayContact','AirspaceDefinition',\n",
    "        'Altitude']\n",
    "\n",
    "notams = []\n",
    "for u in notam_urls:\n",
    "    try:\n",
    "        data = {'url':u}\n",
    "        geom = None\n",
    "        notam_site = requests.get(u)\n",
    "        notam_soup = BeautifulSoup(notam_site.content,'html.parser')\n",
    "        message = notam_soup.find('form',{'name':'meas'})\n",
    "        message_tr = message.find_all('tr')\n",
    "        for mes_tr in message_tr:\n",
    "            shp_zip_path = None\n",
    "            tables = mes_tr.find_all(\"table\")\n",
    "\n",
    "            for tbl in tables:            \n",
    "                tds = tbl.find_all('td')\n",
    "\n",
    "                #process shapefile for geometry if it exists\n",
    "                for a in tds[1].find_all('a', href=True):\n",
    "                    if a['href'].endswith('.shp.zip'):\n",
    "                        shp_url = 'https://tfr.faa.gov/save_pages/' + a['href']\n",
    "                        shp = requests.get(shp_url)\n",
    "                        shp_zip_path = os.path.join(NOTAM_DIR,'shapefile.shp.zip')\n",
    "                        with open(shp_zip_path, 'wb') as outfile:\n",
    "                            outfile.write(shp.content)\n",
    "                        #break\n",
    "\n",
    "                    if not shp_zip_path is None and os.path.isfile(shp_zip_path):\n",
    "                        with zipfile.ZipFile(shp_zip_path,'r') as z:\n",
    "                            z.extractall(NOTAM_DIR)\n",
    "\n",
    "                        shp_path = searchFolder(NOTAM_DIR,['.shp'])[0]\n",
    "                        with arcpy.da.SearchCursor(shp_path,['SHAPE@']) as cursor:\n",
    "                            for row in cursor:\n",
    "                                geom = row[0].projectAs(arcpy.SpatialReference(4326)).JSON\n",
    "\n",
    "                cleanNOTAMDir()\n",
    "\n",
    "                #process NOTAM text\n",
    "                for i in range(len(tds)):                \n",
    "                    text = cleanText(tds[i].text)\n",
    "\n",
    "                    if text in keys:\n",
    "                        value = tds[i+1].text.strip()\n",
    "                        value = value.split('\\n')[0]\n",
    "                        data.update({text:value})\n",
    "                    elif text.startswith('OperatingRestrictionsandRequirements'):\n",
    "                        apmn = []\n",
    "                        for j in range(i+2,len(tds)):\n",
    "                            apmn.append(tds[j].text.strip())\n",
    "                        free_text = ''.join(apmn)\n",
    "                        data.update({'text':free_text,\n",
    "                                    'geom':geom})\n",
    "\n",
    "        if not geom is None: #don't store NOTAMs without Geometry\n",
    "            n = NOTAM.fromDict(data)\n",
    "            notams.append(n)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "f'FOUND {len(notams)} NOTAMS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title: NOTAMs | Type: Feature Service |\n",
    "notam_lyr = gis.content.get(NOTAM_LAYER_ID).layers[0]\n",
    "notam_lyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Try to add each NOTAM to the Feature Service'''\n",
    "if len(notams):\n",
    "    notam_lyr.delete_features(where='1=1')\n",
    "\n",
    "    feats = [notm.toFeature() for notm in notams]\n",
    "    for f in feats:\n",
    "        try:\n",
    "            notam_lyr.edit_features(adds=[f])\n",
    "        except Exception as e:\n",
    "            print(str(e))"
   ]
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Advanced",
   "notebookRuntimeVersion": "7.0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce21b655b4d6c9e397d5ad93d5666c623f49909f6d0cc2f72076dafcf1b3ecfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
